# # Code derived from tensorflow/tensorflow/models/image/imagenet/classify_image.py
# from __future__ import absolute_import
# from __future__ import division
# from __future__ import print_function

# import os.path
# import sys
# import tarfile

# import numpy as np
# from six.moves import urllib
# import tensorflow as tf
# import glob
# import scipy.misc
# import math
# import sys

# MODEL_DIR = '/tmp/imagenet'
# DATA_URL = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'
# softmax = None

# # Call this function with list of images. Each of elements should be a 
# # numpy array with values ranging from 0 to 255.
# def get_inception_score(images, splits=10):
#   assert(type(images) == list)
#   assert(type(images[0]) == np.ndarray)
#   assert(len(images[0].shape) == 3)
#   assert(np.max(images[0]) > 10)
#   assert(np.min(images[0]) >= 0.0)
#   inps = []
#   for img in images:
#     img = img.astype(np.float32)
#     inps.append(np.expand_dims(img, 0))
#   bs = 1
#   with tf.Session() as sess:
#     preds = []
#     n_batches = int(math.ceil(float(len(inps)) / float(bs)))
#     print(n_batches)
#     for i in range(n_batches):
#         #sys.stdout.write(".")
#         #sys.stdout.flush()
#         inp = inps[(i * bs):min((i + 1) * bs, len(inps))]
#         inp = np.concatenate(inp, 0)
#         pred = sess.run(softmax, {'ExpandDims:0': inp})
#         preds.append(pred)
#         if i%1000==0:
#             print(i)
#     preds = np.concatenate(preds, 0)
#     scores = []
#     print("found preds")
#     for i in range(splits):
#       part = preds[(i * preds.shape[0] // splits):((i + 1) * preds.shape[0] // splits), :]
#       kl = part * (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))
#       kl = np.mean(np.sum(kl, 1))
#       scores.append(np.exp(kl))
#     return np.mean(scores), np.std(scores)

# # This function is called automatically.
# def _init_inception():
#   global softmax
#   if not os.path.exists(MODEL_DIR):
#     os.makedirs(MODEL_DIR)
#   filename = DATA_URL.split('/')[-1]
#   filepath = os.path.join(MODEL_DIR, filename)
#   if not os.path.exists(filepath):
#     def _progress(count, block_size, total_size):
#       sys.stdout.write('\r>> Downloading %s %.1f%%' % (
#           filename, float(count * block_size) / float(total_size) * 100.0))
#       sys.stdout.flush()
#     filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)
#     print()
#     statinfo = os.stat(filepath)
#     print('Succesfully downloaded', filename, statinfo.st_size, 'bytes.')
#   tarfile.open(filepath, 'r:gz').extractall(MODEL_DIR)
#   with tf.gfile.FastGFile(os.path.join(
#       MODEL_DIR, 'classify_image_graph_def.pb'), 'rb') as f:
#     graph_def = tf.GraphDef()
#     graph_def.ParseFromString(f.read())
#     _ = tf.import_graph_def(graph_def, name='')
#   # Works with an arbitrary minibatch size.
#   with tf.Session() as sess:
#     pool3 = sess.graph.get_tensor_by_name('pool_3:0')
#     ops = pool3.graph.get_operations()
#     for op_idx, op in enumerate(ops):
#         for o in op.outputs:
#             shape = o.get_shape()
#             shape = [s.value for s in shape]
#             new_shape = []
#             for j, s in enumerate(shape):
#                 if s == 1 and j == 0:
#                     new_shape.append(None)
#                 else:
#                     new_shape.append(s)
#             o.set_shape(tf.TensorShape(new_shape))
#     w = sess.graph.get_operation_by_name("softmax/logits/MatMul").inputs[1]
#     logits = tf.matmul(tf.squeeze(pool3, [1, 2]), w)
#     softmax = tf.nn.softmax(logits)

# if softmax is None:
#   _init_inception()


'''
From https://github.com/tsc2017/Inception-Score
Code derived from https://github.com/openai/improved-gan/blob/master/inception_score/model.py and https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py
Usage:
    Call get_inception_score(images, splits=10)
Args:
    images: A numpy array with values ranging from 0 to 255 and shape in the form [N, 3, HEIGHT, WIDTH] where N, HEIGHT and WIDTH can be arbitrary. A dtype of np.uint8 is recommended to save CPU memory.
    splits: The number of splits of the images, default is 10.
Returns:
    Mean and standard deviation of the Inception Score across the splits.
'''

import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
import tensorflow_gan as tfgan
import os
import functools
import numpy as np
import time
from tensorflow.python.ops import array_ops
# pip install tensorflow-gan
import tensorflow_gan as tfgan
session=tf.compat.v1.InteractiveSession()
# A smaller BATCH_SIZE reduces GPU memory usage, but at the cost of a slight slowdown
BATCH_SIZE = 64
INCEPTION_TFHUB = 'https://tfhub.dev/tensorflow/tfgan/eval/inception/1'
INCEPTION_OUTPUT = 'logits'

# Run images through Inception.
inception_images = tf.compat.v1.placeholder(tf.float32, [None, 3, None, None], name = 'inception_images')
def inception_logits(images = inception_images, num_splits = 1):
    images = tf.transpose(images, [0, 2, 3, 1])
    size = 299
    images = tf.compat.v1.image.resize_bilinear(images, [size, size])
    generated_images_list = array_ops.split(images, num_or_size_splits = num_splits)
    logits = tf.map_fn(
        fn = tfgan.eval.classifier_fn_from_tfhub(INCEPTION_TFHUB, INCEPTION_OUTPUT, True),
        elems = array_ops.stack(generated_images_list),
        parallel_iterations = 8,
        back_prop = False,
        swap_memory = True,
        name = 'RunClassifier')
    logits = array_ops.concat(array_ops.unstack(logits), 0)
    return logits

logits=inception_logits()

def get_inception_probs(inps):
    session=tf.get_default_session()
    n_batches = int(np.ceil(float(inps.shape[0]) / BATCH_SIZE))
    preds = np.zeros([inps.shape[0], 1000], dtype = np.float32)
    for i in range(n_batches):
        inp = inps[i * BATCH_SIZE:(i + 1) * BATCH_SIZE] / 255. * 2 - 1
        preds[i * BATCH_SIZE : i * BATCH_SIZE + min(BATCH_SIZE, inp.shape[0])] = session.run(logits,{inception_images: inp})[:, :1000]
    preds = np.exp(preds) / np.sum(np.exp(preds), 1, keepdims=True)
    return preds

def preds2score(preds, splits=10):
    scores = []
    for i in range(splits):
        part = preds[(i * preds.shape[0] // splits):((i + 1) * preds.shape[0] // splits), :]
        kl = part * (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))
        kl = np.mean(np.sum(kl, 1))
        scores.append(np.exp(kl))
    return np.mean(scores), np.std(scores)

def get_inception_score(images, splits=10):
    assert(type(images) == np.ndarray)
    assert(len(images.shape) == 4)
    assert(images.shape[1] == 3)
    assert(np.min(images[0]) >= 0 and np.max(images[0]) > 10), 'Image values should be in the range [0, 255]'
    print('Calculating Inception Score with %i images in %i splits' % (images.shape[0], splits))
    start_time=time.time()
    preds = get_inception_probs(images)
    mean, std = preds2score(preds, splits)
    print('Inception Score calculation time: %f s' % (time.time() - start_time))
    return mean, std  # Reference values: 11.38 for 50000 CIFAR-10 training set images, or mean=11.31, std=0.10 if in 10 splits.